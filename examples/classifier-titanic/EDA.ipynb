{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55b5657-529d-408f-820e-01102fbfd647",
   "metadata": {},
   "source": [
    "# Titanic Kaggle challenge as seen by Xingu\n",
    "\n",
    "Objective is to create a training pipeline using Xingu framework. But first we'll make a small exploratory data analisys, use conclusions to write a DataProvider and then train and use it for batch predictions.\n",
    "\n",
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7850b-d459-4649-8211-345f701ab740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd30e3-1b19-412e-868b-5f42d5f275ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pandas.read_csv('data/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1caf65-122b-49ba-a2d1-d3e4f7475b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a30a3b-f465-4d4a-bb65-98e8fd7d40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Age.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e6ee2-66e8-43e5-81a0-bd22d3c7d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ranges     = [0,    15,      50,      100,      numpy.inf]\n",
    "age_categories = [   1,       2,       3,       4            ]\n",
    "# 1=child, 2=adult, 3=elder, 4=unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f822f4-c03e-4c93-8338-b37edc926913",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode=['Sex','Embarked']\n",
    "encoders={\n",
    "    col: sklearn.preprocessing.OrdinalEncoder().fit(df[[col]].dropna())\n",
    "    for col in encode\n",
    "}\n",
    "\n",
    "(\n",
    "    df\n",
    "    .set_index('PassengerId')\n",
    "    .dropna(subset=encode)\n",
    "    .assign(\n",
    "        Sex_encoded      = lambda table: encoders['Sex'].transform(table[['Sex']]).astype(int),\n",
    "        Embarked_encoded = lambda table: encoders['Embarked'].transform(table[['Embarked']]).astype(int),\n",
    "        Age_encoded      = lambda table: pandas.cut(\n",
    "            x=table.Age.fillna(numpy.inf),\n",
    "            bins=age_ranges,\n",
    "            labels=age_categories\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2b4d3-14e4-43af-a882-5aa45133aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_features=\"\"\"\n",
    "    Pclass\n",
    "    Sex\n",
    "    Age\n",
    "    SibSp\n",
    "    Parch\n",
    "    Fare\n",
    "    Embarked\n",
    "\"\"\"\n",
    "\n",
    "x_estimator_features=\"\"\"\n",
    "    Pclass\n",
    "    Age_encoded\n",
    "    SibSp\n",
    "    Parch\n",
    "    Fare\n",
    "    Sex_encoded\n",
    "    Embarked_encoded\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439b348-b839-49e7-9063-fe40fe7f420f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Embarked.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d8b5a4-8325-48e5-ba1e-280521d497ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df\n",
    "    .pipe(\n",
    "        lambda table: table.join(table.sample(frac=0.2,random_state=42).assign(split='test').split)\n",
    "    )\n",
    "    .assign(\n",
    "        split=lambda table: table.split.fillna('train')\n",
    "    )\n",
    "    .split.value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fbe353-faec-48df-a469-1341347d8e48",
   "metadata": {},
   "source": [
    "## Train with Xingu\n",
    "\n",
    "We used the conclusions above to write a `xingu.DataProvider` in class `DPTitanicSurvivor`. We've also implemented a quite advanced `xingu.Estimator` which uses sklearn's StratifiedKFold with Optuna to optimize, with its genetic algorithms, an XGBoostClassifier ensamble of 3 members.\n",
    "\n",
    "Let's start by installing and configuring Xingu... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c9478-d895-45bf-8939-64115f4fb73b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U xingu xgboost optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51c3275-657f-4852-b201-fe17312a9db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm models/* plots/* xingu.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c07f8-9d77-463a-8f6a-95817d88345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import xingu\n",
    "\n",
    "# Configure logging for Xingu\n",
    "logger=logging.getLogger('xingu')\n",
    "FORMATTER = logging.Formatter(\"%(asctime)s|%(levelname)s|%(name)s|%(message)s\")\n",
    "HANDLER = logging.StreamHandler()\n",
    "HANDLER.setFormatter(FORMATTER)\n",
    "logger.addHandler(HANDLER)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "os.environ.update(\n",
    "    dict(\n",
    "        HYPEROPT_STRATEGY     = 'dp',\n",
    "        BATCH_PREDICT         = 'true',\n",
    "        BATCH_PREDICT_SAVE_ESTIMATIONS = 'true',\n",
    "        DATAPROVIDER_FOLDER   = 'dataproviders',\n",
    "        TRAINED_MODELS_PATH   = 'models',\n",
    "        SAVE_SETS             = 'true',\n",
    "        PLOTS_PATH            = 'plots',\n",
    "        PLOTS_FORMAT          = 'png,svg',\n",
    "        XINGU_DB_URL          = \"sqlite:///xingu.db?check_same_thread=False\",\n",
    "        # DATASOURCE_CACHE_PATH = 's3://pan-dl-prd-sdbx-user-modcredito-sens/xingu-datasource-cache/',\n",
    "        # DATABASES=\"dl-modcredito-sens|awsathena+rest://athena.us-east-1.amazonaws.com:443/db_pan_dl_sdbx_user_modcredito_sens?work_group=wg_dl_sdbx_user_modcredito_sens&compression=snappy\",\n",
    "        POST_PROCESS          = 'true',\n",
    "        DEBUG                 = 'true',\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957afaa-fdff-4118-9d03-b41d33bed312",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc45ebb-fd58-4e8e-bd76-9a3c3403f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "coach=xingu.Coach(xingu.DataProviderFactory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb0606-cd3c-477b-82fe-7aa782bf3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "coach.team_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c926763-7074-40f4-8bb7-9b9755a4a575",
   "metadata": {},
   "source": [
    "Get best parameters of a certain optimization trial 933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87748ee-3e5b-4bfa-a05c-7cc9b67fb881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "storage=\"sqlite:///models/optimizer.db\"\n",
    "\n",
    "optuna.study.get_all_study_names(storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d2041-c1e6-4c94-9ae6-22db2e22ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "lovely_trial=933\n",
    "\n",
    "optuna.load_study(\n",
    "    study_name='titanic • warm-gatekeeper',\n",
    "    storage=storage\n",
    ").trials[lovely_trial]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4046e0b-4358-4445-a4da-840db2398f71",
   "metadata": {},
   "source": [
    "The resulting parameters should be now included in the DataProvider in `estimator_hyperparams`.\n",
    "Then retrain the model with `HYPEROPT_STRATEGY=\"dp\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07349e8-ab84-4dca-9914-9b9cc96ab032",
   "metadata": {},
   "source": [
    "## Predict in Batch\n",
    "Now get the trained model, use same methods for data cleaning and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b045825-ae49-44ca-ba79-386a2c6372e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=coach.trained['titanic']\n",
    "\n",
    "# Following line is here just to force use of cached parquet, if available\n",
    "model.context='batch_predict'\n",
    "\n",
    "# Get DP’s batch predict SQL queriesp\n",
    "dict_with_queries     = model.dp.get_dataset_sources_for_batch_predict()\n",
    "\n",
    "# Use queries to get multiple DataFrames\n",
    "dict_with_dataframes  = model.data_sources_to_data(dict_with_queries)\n",
    "\n",
    "# Integrate into one DataFrame and apply logic to clean data\n",
    "df                    = model.dp.clean_data_for_batch_predict(dict_with_dataframes)\n",
    "\n",
    "# Feature engineering\n",
    "df                    = model.dp.feature_engineering_for_batch_predict(df)\n",
    "\n",
    "# Resulting DataFrame used for batch predict\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2253d03-e6d5-4395-b10e-4b54d4e1a106",
   "metadata": {},
   "source": [
    "Now predict and prepare for submission to Kaggle.\n",
    "\n",
    "Instead of `.predict()` method, you can also use `.predict_proba()` and you'll get the probabilities for each classifier class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd327b8b-49c4-4ed8-8b9c-dc5c38eeab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    model\n",
    "    .predict(df)\n",
    "    .rename(columns=dict(estimation=model.dp.get_target()))\n",
    "    .to_csv('data/submission.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4278ab45-1d50-47a7-8e6a-6f6d5ab60aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
